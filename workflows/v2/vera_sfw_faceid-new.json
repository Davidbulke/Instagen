{
  "id": "180d8963-c804-4ec2-a774-76516ba891ed",
  "revision": 0,
  "last_node_id": 20,
  "last_link_id": 26,
  "nodes": [
    {
      "id": 9,
      "type": "VAEDecode",
      "pos": [
        1058.1981981981983,
        135.4234234234234
      ],
      "size": [
        210,
        46
      ],
      "flags": {},
      "order": 10,
      "mode": 0,
      "inputs": [
        {
          "name": "samples",
          "type": "LATENT",
          "link": 12
        },
        {
          "name": "vae",
          "type": "VAE",
          "link": 4
        }
      ],
      "outputs": [
        {
          "name": "IMAGE",
          "type": "IMAGE",
          "slot_index": 0,
          "links": [
            13
          ]
        }
      ],
      "properties": {
        "Node name for S&R": "VAEDecode"
      },
      "widgets_values": []
    },
    {
      "id": 18,
      "type": "IPAdapterFaceID",
      "pos": [
        270.1351351351351,
        138.27027027027006
      ],
      "size": [
        270,
        322
      ],
      "flags": {},
      "order": 8,
      "mode": 0,
      "inputs": [
        {
          "name": "model",
          "type": "MODEL",
          "link": 21
        },
        {
          "name": "ipadapter",
          "type": "IPADAPTER",
          "link": 24
        },
        {
          "name": "image",
          "type": "IMAGE",
          "link": 22
        },
        {
          "name": "image_negative",
          "shape": 7,
          "type": "IMAGE",
          "link": null
        },
        {
          "name": "attn_mask",
          "shape": 7,
          "type": "MASK",
          "link": null
        },
        {
          "name": "clip_vision",
          "shape": 7,
          "type": "CLIP_VISION",
          "link": 25
        },
        {
          "name": "insightface",
          "shape": 7,
          "type": "INSIGHTFACE",
          "link": 26
        }
      ],
      "outputs": [
        {
          "name": "MODEL",
          "type": "MODEL",
          "links": [
            23
          ]
        },
        {
          "name": "face_image",
          "type": "IMAGE",
          "links": null
        }
      ],
      "properties": {
        "Node name for S&R": "IPAdapterFaceID"
      },
      "widgets_values": [
        1,
        0.85,
        "linear",
        "concat",
        0,
        1,
        "V only"
      ]
    },
    {
      "id": 5,
      "type": "CLIPTextEncode",
      "pos": [
        225.26126126126135,
        512.2162162162164
      ],
      "size": [
        400,
        200
      ],
      "flags": {},
      "order": 6,
      "mode": 0,
      "inputs": [
        {
          "name": "clip",
          "type": "CLIP",
          "link": 2
        }
      ],
      "outputs": [
        {
          "name": "CONDITIONING",
          "type": "CONDITIONING",
          "slot_index": 0,
          "links": [
            9
          ]
        }
      ],
      "title": "Positive Prompt",
      "properties": {
        "Node name for S&R": "CLIPTextEncode"
      },
      "widgets_values": [
        "(masterpiece, best quality:1.2), \nrealistic portrait photography, \nprofessional Instagram fitness model, \nathletic physique, defined muscles, \ndetailed skin texture, beautiful eyes, \ngym environment, natural lighting"
      ]
    },
    {
      "id": 6,
      "type": "CLIPTextEncode",
      "pos": [
        220.21621621621628,
        763.2252252252252
      ],
      "size": [
        400,
        130
      ],
      "flags": {},
      "order": 7,
      "mode": 0,
      "inputs": [
        {
          "name": "clip",
          "type": "CLIP",
          "link": 3
        }
      ],
      "outputs": [
        {
          "name": "CONDITIONING",
          "type": "CONDITIONING",
          "slot_index": 0,
          "links": [
            10
          ]
        }
      ],
      "title": "Negative Prompt",
      "properties": {
        "Node name for S&R": "CLIPTextEncode"
      },
      "widgets_values": [
        "(worst quality, low quality:1.4), (bad anatomy:1.2), bad hands, bad fingers, blurry, watermark, text, logo, censored, cartoon, anime, 3d render"
      ]
    },
    {
      "id": 7,
      "type": "EmptyLatentImage",
      "pos": [
        685.2612612612613,
        547.5315315315316
      ],
      "size": [
        320,
        106
      ],
      "flags": {},
      "order": 0,
      "mode": 0,
      "inputs": [],
      "outputs": [
        {
          "name": "LATENT",
          "type": "LATENT",
          "slot_index": 0,
          "links": [
            11
          ]
        }
      ],
      "properties": {
        "Node name for S&R": "EmptyLatentImage"
      },
      "widgets_values": [
        1024,
        1024,
        1
      ]
    },
    {
      "id": 10,
      "type": "SaveImage",
      "pos": [
        1337.6936936936936,
        73.98198198198193
      ],
      "size": [
        320,
        270
      ],
      "flags": {},
      "order": 11,
      "mode": 0,
      "inputs": [
        {
          "name": "images",
          "type": "IMAGE",
          "link": 13
        }
      ],
      "outputs": [],
      "properties": {},
      "widgets_values": [
        "vera_sfw_"
      ]
    },
    {
      "id": 3,
      "type": "LoadImage",
      "pos": [
        -154.82882882882885,
        586.846846846847
      ],
      "size": [
        320,
        314.00000000000006
      ],
      "flags": {},
      "order": 1,
      "mode": 0,
      "inputs": [],
      "outputs": [
        {
          "name": "IMAGE",
          "type": "IMAGE",
          "slot_index": 0,
          "links": [
            22
          ]
        },
        {
          "name": "MASK",
          "type": "MASK",
          "links": null
        }
      ],
      "title": "Vera Reference Face",
      "properties": {
        "Node name for S&R": "LoadImage"
      },
      "widgets_values": [
        "MAIN.png",
        "image"
      ]
    },
    {
      "id": 16,
      "type": "CLIPVisionLoader",
      "pos": [
        -138.51351351351346,
        337.0450450450449
      ],
      "size": [
        270,
        58
      ],
      "flags": {},
      "order": 2,
      "mode": 0,
      "inputs": [],
      "outputs": [
        {
          "name": "CLIP_VISION",
          "type": "CLIP_VISION",
          "links": [
            25
          ]
        }
      ],
      "properties": {
        "Node name for S&R": "CLIPVisionLoader"
      },
      "widgets_values": [
        "CLIP-ViT-H-14-laion2B-s32B-b79K.safetensors"
      ]
    },
    {
      "id": 15,
      "type": "IPAdapterModelLoader",
      "pos": [
        -141.5405405405405,
        234.1261261261262
      ],
      "size": [
        270,
        58
      ],
      "flags": {},
      "order": 3,
      "mode": 0,
      "inputs": [],
      "outputs": [
        {
          "name": "IPADAPTER",
          "type": "IPADAPTER",
          "links": [
            24
          ]
        }
      ],
      "properties": {
        "Node name for S&R": "IPAdapterModelLoader"
      },
      "widgets_values": [
        "ip-adapter-faceid-plusv2_sdxl.bin"
      ]
    },
    {
      "id": 1,
      "type": "CheckpointLoaderSimple",
      "pos": [
        -147.76576576576574,
        78.25225225225228
      ],
      "size": [
        320,
        98
      ],
      "flags": {},
      "order": 4,
      "mode": 0,
      "inputs": [],
      "outputs": [
        {
          "name": "MODEL",
          "type": "MODEL",
          "slot_index": 0,
          "links": [
            21
          ]
        },
        {
          "name": "CLIP",
          "type": "CLIP",
          "slot_index": 1,
          "links": [
            2,
            3
          ]
        },
        {
          "name": "VAE",
          "type": "VAE",
          "slot_index": 2,
          "links": [
            4
          ]
        }
      ],
      "properties": {
        "Node name for S&R": "CheckpointLoaderSimple"
      },
      "widgets_values": [
        "realvisxl_v40_bakedvae.safetensors"
      ]
    },
    {
      "id": 8,
      "type": "KSampler",
      "pos": [
        687.2792792792791,
        28.468468468468483
      ],
      "size": [
        320,
        474
      ],
      "flags": {},
      "order": 9,
      "mode": 0,
      "inputs": [
        {
          "name": "model",
          "type": "MODEL",
          "link": 23
        },
        {
          "name": "positive",
          "type": "CONDITIONING",
          "link": 9
        },
        {
          "name": "negative",
          "type": "CONDITIONING",
          "link": 10
        },
        {
          "name": "latent_image",
          "type": "LATENT",
          "link": 11
        }
      ],
      "outputs": [
        {
          "name": "LATENT",
          "type": "LATENT",
          "slot_index": 0,
          "links": [
            12
          ]
        }
      ],
      "properties": {
        "Node name for S&R": "KSampler"
      },
      "widgets_values": [
        518274989751911,
        "randomize",
        30,
        7,
        "dpmpp_2m_sde",
        "karras",
        1
      ]
    },
    {
      "id": 20,
      "type": "IPAdapterInsightFaceLoader",
      "pos": [
        -145.5765765765765,
        452.0720720720721
      ],
      "size": [
        294.51666870117185,
        82
      ],
      "flags": {},
      "order": 5,
      "mode": 0,
      "inputs": [],
      "outputs": [
        {
          "name": "INSIGHTFACE",
          "type": "INSIGHTFACE",
          "links": [
            26
          ]
        }
      ],
      "properties": {
        "Node name for S&R": "IPAdapterInsightFaceLoader"
      },
      "widgets_values": [
        "CPU",
        "antelopev2"
      ]
    }
  ],
  "links": [
    [
      2,
      1,
      1,
      5,
      0,
      "CLIP"
    ],
    [
      3,
      1,
      1,
      6,
      0,
      "CLIP"
    ],
    [
      4,
      1,
      2,
      9,
      1,
      "VAE"
    ],
    [
      9,
      5,
      0,
      8,
      1,
      "CONDITIONING"
    ],
    [
      10,
      6,
      0,
      8,
      2,
      "CONDITIONING"
    ],
    [
      11,
      7,
      0,
      8,
      3,
      "LATENT"
    ],
    [
      12,
      8,
      0,
      9,
      0,
      "LATENT"
    ],
    [
      13,
      9,
      0,
      10,
      0,
      "IMAGE"
    ],
    [
      21,
      1,
      0,
      18,
      0,
      "MODEL"
    ],
    [
      22,
      3,
      0,
      18,
      2,
      "IMAGE"
    ],
    [
      23,
      18,
      0,
      8,
      0,
      "MODEL"
    ],
    [
      24,
      15,
      0,
      18,
      1,
      "IPADAPTER"
    ],
    [
      25,
      16,
      0,
      18,
      5,
      "CLIP_VISION"
    ],
    [
      26,
      20,
      0,
      18,
      6,
      "INSIGHTFACE"
    ]
  ],
  "groups": [
    {
      "id": 1,
      "title": "VERA - SFW IPAdapter FaceID Workflow",
      "bounding": [
        -171.8018018018018,
        -54.576576576576585,
        2069.3693693693695,
        1201.801801801802
      ],
      "color": "#3f789e",
      "font_size": 24,
      "flags": {}
    }
  ],
  "config": {},
  "extra": {
    "info": "Vera SFW FaceID workflow - Uses IPAdapter FaceID Plus V2 for face consistency.",
    "workflowRendererVersion": "LG",
    "ds": {
      "scale": 0.9910714285714286,
      "offset": [
        247.4864864864865,
        155.35135135135133
      ]
    },
    "frontendVersion": "1.36.14"
  },
  "version": 0.4
}